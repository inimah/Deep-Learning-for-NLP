{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Wikipedia Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datasets provided (in download link) is compressed version of wikipedia\n",
    "# First download text8.zip as explained in download_links.md\n",
    "import os\n",
    "import zipfile\n",
    "import numpy as np\n",
    "import collections\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data into a list of strings.\n",
    "def read_data(filename):\n",
    "    \"\"\"Extract the first file enclosed in a zip file as a list of words.\"\"\"\n",
    "    with zipfile.ZipFile(filename) as f:\n",
    "        data = tf.compat.as_str(f.read(f.namelist()[0])).split()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the list is tokenized version (words) from document corpus\n",
    "vocabulary = read_data('text8.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['anarchism', 'originated', 'as', 'a', 'term']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# try printing first 5 words in list\n",
    "vocabulary[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building vocabulary index and training sets from n-chosen vocabulary size \n",
    "# (e.g 10.000 most frequent words)\n",
    "# training sets is integer format of list of words\n",
    "def build_dataset(words, n_words):\n",
    "    \"\"\"Process raw inputs into a dataset.\"\"\"\n",
    "    count = [['UNK', -1]]\n",
    "    count.extend(collections.Counter(words).most_common(n_words - 1))\n",
    "    dictionary = dict()\n",
    "    for word, _ in count:\n",
    "        dictionary[word] = len(dictionary)\n",
    "    data = list()\n",
    "    unk_count = 0\n",
    "    for word in words:\n",
    "        if word in dictionary:\n",
    "            index = dictionary[word]\n",
    "        else:\n",
    "            index = 0  # dictionary['UNK']\n",
    "            unk_count += 1\n",
    "        data.append(index)\n",
    "    count[0][1] = unk_count\n",
    "    reversed_dictionary = dict(zip(dictionary.values(), dictionary.keys()))\n",
    "    return data, count, dictionary, reversed_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 10000\n",
    "data, count, dictionary, reverse_dictionary = build_dataset(vocabulary, vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vocabulary size as previously chosen \n",
    "len(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('hit', 1068),\n",
       " ('baptism', 3244),\n",
       " ('physical', 659),\n",
       " ('cross', 713),\n",
       " ('young', 527),\n",
       " ('byron', 6469),\n",
       " ('asking', 5590),\n",
       " ('dissolution', 6964),\n",
       " ('scales', 4805),\n",
       " ('baghdad', 7164)]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print 10 first word and its index in vocabulary\n",
    "list(dictionary.items())[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17005207"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of training sets (bag-of-words)\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5237, 3081, 12, 6, 195]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# integer (numerical) format as input of model\n",
    "data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 'UNK'),\n",
       " (1, 'the'),\n",
       " (2, 'of'),\n",
       " (3, 'and'),\n",
       " (4, 'one'),\n",
       " (5, 'in'),\n",
       " (6, 'a'),\n",
       " (7, 'to'),\n",
       " (8, 'zero'),\n",
       " (9, 'nine')]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reverse vocabulary index\n",
    "list(reverse_dictionary.items())[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reconstructing back integer list to string format of original training sets\n",
    "def indexToWords(vocab,data):\n",
    "    strData = [vocab[i] for i in data]\n",
    "    return strData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "strData = indexToWords(reverse_dictionary,data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['anarchism',\n",
       " 'originated',\n",
       " 'as',\n",
       " 'a',\n",
       " 'term',\n",
       " 'of',\n",
       " 'abuse',\n",
       " 'first',\n",
       " 'used',\n",
       " 'against']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strData[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import _pickle as cPickle\n",
    "# saving file into pickle format\n",
    "def savePickle(dataToWrite,pickleFilename):\n",
    "\tf = open(pickleFilename, 'wb')\n",
    "\tcPickle.dump(dataToWrite, f)\n",
    "\tf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading file in pickle format\n",
    "def readPickle(pickleFilename):\n",
    "\tf = open(pickleFilename, 'rb')\n",
    "\tobj = cPickle.load(f)\n",
    "\tf.close()\n",
    "\treturn obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save all preprocessed data into pickle (so that it can be reused anytime \n",
    "# without repeating preprocessing stage)\n",
    "savePickle(data,'wikipedia_trainset')\n",
    "savePickle(dictionary,'wikipedia_vocab')\n",
    "savePickle(reverse_dictionary,'wikipedia_reversevocab')\n",
    "savePickle(count,'wikipedia_tf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. TED Talk "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datasets provided is english script of TED Talk video\n",
    "# Sample of raw text as follows:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "<seekvideo id=\"835\">Mark Twain summed up what I take to be</seekvideo>\n",
    "<seekvideo id=\"2990\">one of the fundamental problems of cognitive science</seekvideo>\n",
    "<seekvideo id=\"6110\">with a single witticism.</seekvideo>\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. PennTreeBank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unzip the downloaded file \n",
    "# Data sets provided is in data/, example of raw data as follows\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "he will continue to report to donald <unk> president and chief executive officer \n",
    "mr. stevens was executive vice president of this <unk> holding company \n",
    "arthur a. hatch N was named executive vice president of the company \n",
    "he was previously president of the company 's eastern edison co. unit \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. IMDB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 20NewsGroups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Amazon Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Sentiment analysis:\n",
    "# Data sets is provided with binary labels: Negative (1) and Positive (2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "__label__1 The Worst!: A complete waste of time. Typographical errors, poor grammar, and a totally pathetic plot add up to absolutely nothing. I'm embarrassed for this author and very disappointed I actually paid for this book.\n",
    "__label__2 Great book: This was a great book,I just could not put it down,and could not read it fast enough. Boy what a book the twist and turns in this just keeps you guessing and wanting to know what is going to happen next. This book makes you fall in love and can heat you up,it can also make you so angery. this book can make you go throu several of your emotions. This is a quick read romance. It is something that you will want to end your day off with if you read at night.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Lingspam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Enron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
